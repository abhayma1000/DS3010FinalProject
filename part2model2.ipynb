{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Load in the tensors and configuration from Config class and yeah. Build the bert model locally and have an option to load in another pre-trained one\n",
    "\n",
    "Features\n",
    "\n",
    "* Initialize from scratch\n",
    "* Initialize from pre-trained model\n",
    "* Set freezable parameters\n",
    "Load in tensor data\n",
    "* Create data loaders\n",
    "* Predict function(nn inputs and input_ids/attention mask)\n",
    "* Predict function(nn inputs and text)\n",
    "* Evaluation function(some data loader)\n",
    "* Train one epoch\n",
    "* Train multiple epochs\n",
    "    * Calls train one epoch but has more overall reporting stats, perhaps return history object\n",
    "* Save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import constants\n",
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'part2model2'\n",
    "output_folder, num = utils.get_next_output_folder(f'outputs/{filename}_output')\n",
    "config = constants.Config(filename,\n",
    "                          output_folder = output_folder,\n",
    "                          num_iteration=num,\n",
    "                          epochs=1,\n",
    "                          load_tensor_path='outputs/part2preprocessing_output_16',\n",
    "                          )\n",
    "print(\"Output folder: \", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pickle\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, get_linear_schedule_with_warmup, BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.display import display, clear_output\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import GPUtil\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('stopwords')\n",
    "try:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nltk.download('averaged_perceptron_tagger_eng')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "os.system('./venv/bin/python -m spacy download en_core_web_sm')\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nltk.download('punkt_tab')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import shap.maskers\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\tdef __init__(self, \n",
    "\t\t\t\t load_path=config.load_in_model_path, \n",
    "\t\t\t\t batch_size=config.batch_size, \n",
    "\t\t\t\t epochs=config.epochs, \n",
    "\t\t\t\t tokenizer_max_length=config.tokenizer_max_length, \n",
    "\t\t\t\t nn_input_size=config.nn_input_size):\n",
    "\t\t\n",
    "\t\tsuper(BertClassifier, self).__init__()\n",
    "\t\t\n",
    "\t\tself.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\t\tprint(\"Running on device: \", self.device)\n",
    "\n",
    "\t\tprint(\"Constructing model...\")\n",
    "\t\tself.bert = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
    "\t\tself.bert_output_size = self.bert.config.hidden_size\n",
    "\n",
    "\t\tself.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\t\tself.nn_output_size = 12\n",
    "\t\tself.nn_layers = nn.Sequential(\n",
    "\t\t\tnn.Linear(nn_input_size, 12),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(12, 12),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(12, self.nn_output_size),\n",
    "\t\t\tnn.ReLU()\n",
    "\t\t).to(self.device)\n",
    "\n",
    "\t\tself.final_layers = nn.Sequential(\n",
    "\t\t\tnn.Linear(self.bert_output_size + self.nn_output_size, 12),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(12, 12),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(12, 1)\n",
    "\t\t).to(self.device)\n",
    "\n",
    "\t\tself.optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5, eps=1e-8)\n",
    "\t\tself.scheduler = self.get_scheduler(self.optimizer, None)\n",
    "\t\tself.criterion = nn.BCEWithLogitsLoss()\n",
    "\t\t\t\n",
    "\t\tif load_path:\n",
    "\t\t\tprint(\"Loading in model...\")\n",
    "\t\t\tself.load_model(load_path)\n",
    "\n",
    "\t\tself.batch_size=batch_size\n",
    "\t\tself.epochs = epochs\n",
    "\t\tself.tokenizer_max_length = tokenizer_max_length\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "\tdef forward(self, input_ids, attention_mask, nn_input):\n",
    "\t\tbert_outputs = self.bert(input_ids, attention_mask)\n",
    "\t\tpooled_output = bert_outputs.pooler_output\n",
    "\n",
    "\t\tnn_outputs = self.nn_layers(nn_input)\n",
    "\t\tfinal_input = torch.cat((pooled_output, nn_outputs), dim=1)\n",
    "\t\treturn self.final_layers(final_input)\n",
    "\n",
    "\n",
    "\n",
    "\tdef train_model(self, train_dataloader: DataLoader,\n",
    "\t\t   val_dataloader: DataLoader,\n",
    "\t\t   email_updates=False,\n",
    "\t\t   email_every=1):\n",
    "\t\tprint(\"Training model...\")\n",
    "\n",
    "\t\ttrain_losses = [0]\n",
    "\t\tval_losses = [0]\n",
    "\t\ttrain_accuracies = [0]\n",
    "\t\tval_accuracies = [0]\n",
    "\n",
    "\t\tbest_val_acc = 0.0\n",
    "\n",
    "\t\t# Set these when training\n",
    "\t\tself.optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5, eps=1e-8)\n",
    "\t\tself.scheduler = self.get_scheduler(self.optimizer, train_dataloader)\n",
    "\t\tself.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\t\tfor epoch in range(self.epochs):\n",
    "\t\t\tprint(f\"\\n===== Epoch {epoch + 1}/{self.epochs} =====\")\n",
    "\n",
    "\t\t\tif email_updates and epoch % email_every == 0:\n",
    "\t\t\t\tutils.send_email(f\"✅ Training {config.filename} model at {epoch + 1} epochs\", \n",
    "\t\t\t\t\t f\"Time so far: {utils.get_time_from_start(start_time)}\\nConfig: {config.__dict__}\\nTrain acc: {train_accuracies[-1]}\\nVal acc: {val_accuracies[-1]}\\nAbhayUpdateEmail\")\n",
    "\n",
    "\n",
    "\t\t\ttrain_loss, train_acc = self.train_epoch(train_dataloader)\n",
    "\t\t\ttrain_losses.append(train_loss)\n",
    "\t\t\ttrain_accuracies.append(train_acc)\n",
    "\n",
    "\t\t\tval_loss, val_acc = self.evaluate(val_dataloader, epoch)\n",
    "\t\t\tval_losses.append(val_loss)\n",
    "\t\t\tval_accuracies.append(val_acc)\n",
    "\n",
    "\t\t\tif val_acc > best_val_acc:\n",
    "\t\t\t\tbest_val_acc = val_acc\n",
    "\t\t\t\tself.save_model()\n",
    "\t\t\n",
    "\t\treturn train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "\t\n",
    "\tdef train_epoch(self, train_dataloader: DataLoader):\n",
    "\t\tself.train()\n",
    "\n",
    "\t\ttrain_loss = 0\n",
    "\t\tcorrect_predictions = 0\n",
    "\t\ttotal_samples = 0\n",
    "\n",
    "\t\tfor step, batch in enumerate(train_dataloader):\n",
    "\t\t\tprint(f\"Progress: {step + 1}/{len(train_dataloader)}\", end='\\r')\n",
    "\n",
    "\t\t\tself.optimizer.zero_grad()\n",
    "\n",
    "\t\t\tb_input_ids = batch[0].to(self.device)\n",
    "\t\t\tb_input_mask = batch[1].to(self.device)\n",
    "\t\t\tb_nn_input = batch[2].to(self.device)\n",
    "\t\t\tb_labels = batch[3].to(self.device)\n",
    "\n",
    "\t\t\tb_labels = b_labels.float().view(-1, 1)\n",
    "\n",
    "\t\t\toutput = self.forward(b_input_ids, b_input_mask, b_nn_input)\n",
    "\t\t\tloss = self.criterion(output, b_labels)\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\t\t\tself.scheduler.step()\n",
    "\n",
    "\t\t\ttrain_loss += loss.item()\n",
    "\n",
    "\t\t\tpreds = torch.round(torch.sigmoid(output))\n",
    "\n",
    "\t\t\tcorrect_predictions += torch.sum(preds == b_labels)\n",
    "\t\t\ttotal_samples += b_labels.size(0)\n",
    "\t\t\n",
    "\t\ttrain_loss /= len(train_dataloader)\n",
    "\t\ttrain_acc = (correct_predictions / total_samples).item()\n",
    "\n",
    "\t\tprint(\"Training Loss: \", train_loss)\n",
    "\t\tprint(\"Train accuracy: \", train_acc)\n",
    "\t\treturn train_loss, train_acc,\n",
    "\n",
    "\t\n",
    "\tdef predict(self, test_dataloader: DataLoader):\n",
    "\t\tself.eval()\n",
    "\n",
    "\t\tall_preds = []\n",
    "\t\tall_labels = []\n",
    "\n",
    "\t\tfor step, batch in enumerate(test_dataloader):\n",
    "\t\t\tprint(f\"Progress: {step + 1}/{len(test_dataloader)}\", end='\\r')\n",
    "\n",
    "\t\t\tb_input_ids = batch[0].to(self.device)\n",
    "\t\t\tb_input_mask = batch[1].to(self.device)\n",
    "\t\t\tb_nn_input = batch[2].to(self.device)\n",
    "\t\t\tb_labels = batch[3].to(self.device)\n",
    "\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\toutput = self.forward(b_input_ids, b_input_mask, b_nn_input)\n",
    "\t\t\t\tpreds = torch.round(torch.sigmoid(output))\n",
    "\n",
    "\t\t\t\tall_preds.extend(preds.cpu().numpy())\n",
    "\t\t\t\tall_labels.extend(b_labels.cpu().numpy())\n",
    "\t\t\n",
    "\t\treturn np.array(all_preds), np.array(all_labels).reshape(-1, 1)\n",
    "\n",
    "\tdef predict_single(self, text: str, nn_input: torch.Tensor, sigmoid=True):\n",
    "\t\tself.eval()\n",
    "\n",
    "\t\tencoded_text = self.tokenizer.encode_plus(\n",
    "\t\t\ttext,\n",
    "\t\t\tadd_special_tokens=True,\n",
    "\t\t\tpadding='max_length',\n",
    "\t\t\tmax_length=config.tokenizer_max_length,\n",
    "\t\t\tpad_to_max_length=True,\n",
    "\t\t\treturn_attention_mask=True,\n",
    "\t\t\treturn_tensors='pt',\n",
    "\t\t\ttruncation=True\n",
    "\t\t)\n",
    "\n",
    "\t\tinput_ids = encoded_text['input_ids'].to(self.device)\n",
    "\t\tattention_mask = encoded_text['attention_mask'].to(self.device)\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutput = self.forward(input_ids, attention_mask, nn_input)\n",
    "\t\t\tif sigmoid:\n",
    "\t\t\t\tpred = torch.round(torch.sigmoid(output))\n",
    "\t\t\telse:\n",
    "\t\t\t\tpred = output\n",
    "\n",
    "\t\treturn pred.item()\n",
    "\t\n",
    "\tdef new_predict_multiple_output_shap(self, text_and_nn_input: np.array):\n",
    "\t\ttext_inputs = text_and_nn_input[:, 0].tolist()\n",
    "\n",
    "\t\tnumerical_inputs = torch.tensor(text_and_nn_input[:, 1:].astype(np.float32)).to(self.device)\n",
    "\n",
    "\t\treturn self.predict_multiple_output_shap(text_inputs, numerical_inputs)\n",
    "\n",
    "\t# def predict_single_output_shap(self, text: str, nn_input: torch.Tensor):\n",
    "\t# \tvalue = self.predict_single(text, nn_input)\n",
    "\n",
    "\t# \tlabel, opp_label = (\"OPEN\", \"CLOSE\") if value > 0.5 else (\"CLOSE\", \"OPEN\")\n",
    "\n",
    "\t# \treturn np.array([[{'label': label, 'score': value}, {'label': opp_label, 'score': 1.0 - value}]])\n",
    "\n",
    "\tdef predict_multiple_output_shap(self, texts: list[str], nn_input: torch.Tensor):\n",
    "\t\treturn np.array([self.predict_single(text, nn_input[i].view(1, -1)) for i, text in enumerate(texts)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tdef evaluate(self, test_dataloader: DataLoader, epoch=None):\n",
    "\t\tself.eval()\n",
    "\t\t\n",
    "\t\tpreds, labels = self.predict(test_dataloader)\n",
    "\t\tpreds = np.array(preds)\n",
    "\t\tlabels = np.array(labels)\n",
    "\t\tprint(\"Classification Report\" + (f\" Epoch {epoch}\" if epoch else \"\") + \":\")\n",
    "\t\tprint(classification_report(labels, preds))\n",
    "\t\tprint(\"Number of examples: \", len(labels))\n",
    "\t\tprint(\"Number of correct predictions: \", (preds == labels).sum())\n",
    "\n",
    "\t\tpreds_tensor, labels_tensor = torch.tensor(preds), torch.tensor(labels)\n",
    "\t\tnum_classes = 2\n",
    "\t\tprint(\"Accuracy: \", torchmetrics.functional.accuracy(preds_tensor, labels_tensor, num_classes=num_classes, task='binary').item())\n",
    "\t\tprint(\"Macro F1 score: \", f1_score(preds_tensor, labels_tensor, num_classes=num_classes, average='macro', task='binary').item())\n",
    "\t\tprint(\"Micro F1 score: \", f1_score(preds_tensor, labels_tensor, num_classes=num_classes, average='micro', task='binary').item())\n",
    "\t\tprint(\"Weighted F1 score: \", f1_score(preds_tensor, labels_tensor, num_classes=num_classes, average='weighted', task='binary').item())\n",
    "\n",
    "\n",
    "\n",
    "\t\tloss = self.criterion(torch.tensor(preds).view(-1, 1), torch.tensor(labels).view(-1, 1)).item()\n",
    "\n",
    "\t\tacc = (preds == labels).mean().item()\n",
    "\n",
    "\t\tprint(\"Accuracy: \", acc)\n",
    "\t\tprint(\"Loss: \", loss)\n",
    "\n",
    "\t\treturn loss, acc\n",
    "\n",
    "\n",
    "\tdef load_strings_data_tensors(self, which='test', tensor_path=config.load_tensor_path):\n",
    "\t\ttensors = torch.load(os.path.join(tensor_path, f'all_tensors_percentage_1_{which}_strings.pth'))\n",
    "\n",
    "\t\tprint(f\"Loading in string tensors from {which} dataset...\")\n",
    "\t\tprint(\"Number of samples: \", len(tensors['padded_strings']))\n",
    "\t\tprint(\"Dims of padded_strings: \", tensors['padded_strings'].shape)\n",
    "\t\tprint(\"Dims of nn_inputs: \", tensors['nn_inputs'].shape)\n",
    "\t\tprint(\"Dims of outputs: \", tensors['outputs'].shape)\n",
    "\n",
    "\t\tprint(\"Decoding text...\")\n",
    "\t\tdecoded_text = [\"\".join([chr(i) for i in row if i != 0]) for row in tensors['padded_strings'].tolist()]\n",
    "\n",
    "\t\tprint(\"Decoded text sample: \", decoded_text[:5])\n",
    "\n",
    "\t\treturn decoded_text, tensors['nn_inputs'], tensors['outputs']\n",
    "\n",
    "\n",
    "\n",
    "\tdef load_data_tensors(self, which='train', tensor_path=config.load_tensor_path):\n",
    "\t\ttensors = torch.load(os.path.join(tensor_path, f'all_tensors_percentage_1_{which}.pth'))\n",
    "\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tprint(f\"Loading in tensors from {which} dataset...\")\n",
    "\t\tprint(\"Number of samples: \", len(tensors['input_ids']))\n",
    "\t\tprint(\"Dims of input_ids: \", tensors['input_ids'].shape)\n",
    "\t\tprint(\"Dims of attention_masks: \", tensors['attention_masks'].shape)\n",
    "\t\tprint(\"Dims of nn_inputs: \", tensors['nn_inputs'].shape)\n",
    "\t\tprint(\"Dims of outputs: \", tensors['outputs'].shape)\n",
    "\t\t\n",
    "\t\treturn tensors['input_ids'], tensors['attention_masks'], tensors['nn_inputs'], tensors['outputs']\n",
    "\n",
    "\tdef create_dataloaders(self, \n",
    "\t\t\t\t\t\tinput_ids: torch.Tensor,\n",
    "\t\t\t\t\t\tattention_masks: torch.Tensor,\n",
    "\t\t\t\t\t\tnn_inputs: torch.Tensor,\n",
    "\t\t\t\t\t\toutputs: torch.Tensor,\n",
    "\t\t\t\t\t\tsampler: SequentialSampler):\n",
    "\t\n",
    "\t\tdataset = TensorDataset(input_ids, attention_masks, nn_inputs, outputs)\n",
    "\n",
    "\t\tprint(\"Creating dataloaders...\")\n",
    "\t\tprint(\"Number of samples: \", len(dataset))\n",
    "\n",
    "\t\tdataloader = DataLoader(\n",
    "\t\t\tdataset,\n",
    "\t\t\tsampler=sampler(dataset),\n",
    "\t\t\tbatch_size=self.batch_size\n",
    "\t\t)\n",
    "\n",
    "\t\treturn dataloader\n",
    "\t\n",
    "\tdef get_scheduler(self, optimizer, train_dataloader=None):\n",
    "\t\tif train_dataloader is None:\n",
    "\t\t\ttotal_steps=100000\n",
    "\t\telse:\n",
    "\t\t\ttotal_steps = len(train_dataloader) * self.epochs\n",
    "\t\tscheduler = get_linear_schedule_with_warmup(\n",
    "\t\t\toptimizer,\n",
    "\t\t\tnum_warmup_steps=0,\n",
    "\t\t\tnum_training_steps=total_steps\n",
    "\t\t)\n",
    "\t\treturn scheduler\n",
    "\n",
    "\t\n",
    "\tdef freeze_layers(self, num_layers_left_unfrozen: int):\n",
    "\t\tfor param in self.bert.parameters():\n",
    "\t\t\tparam.requires_grad = False\n",
    "\t\t\n",
    "\t\tfor param in self.bert.encoder.layer[num_layers_left_unfrozen:].parameters():\n",
    "\t\t\tparam.requires_grad = True\n",
    "\t\t\n",
    "\t\n",
    "\t\t\n",
    "\n",
    "\tdef save_model(self, output_folder=config.output_folder):\n",
    "\t\tsave_path = os.path.join(output_folder, 'bert_hybrid.pth')\n",
    "\t\ttokenizer_save_path = os.path.join(output_folder, 'tokenizer.pth')\n",
    "\t\ttorch.save({\n",
    "\t\t\t'bert': self.bert.state_dict(),\n",
    "\t\t\t'nn_layers': self.nn_layers.state_dict(),\n",
    "\t\t\t'final_layers': self.final_layers.state_dict(),\n",
    "\t\t\t'optimizer': self.optimizer.state_dict(),\n",
    "\t\t\t'scheduler': self.scheduler.state_dict(),\n",
    "\t\t\t'criterion': self.criterion.state_dict()\n",
    "\t\t}, save_path)\n",
    "\n",
    "\t\tself.tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\t\tprint(\"Model saved to: \", save_path)\n",
    "\t\tprint(\"Tokenizer saved to: \", tokenizer_save_path)\n",
    "\n",
    "\t\treturn save_path, tokenizer_save_path\n",
    "\n",
    "\n",
    "\n",
    "\tdef load_model(self, model_path=config.load_in_model_path):\n",
    "\t\tprint(\"Loading in model from : \", model_path)\n",
    "\t\ttry:\n",
    "\t\t\tcheckpoint = torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\t\texcept:\n",
    "\t\t\twith open(model_path, \"rb\") as f:\n",
    "\t\t\t\tbuffer = io.BytesIO(f.read())\n",
    "\n",
    "\t\t\tcheckpoint = torch.load(buffer, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\t\tprint(\"Successfully loaded big tensor...\")\n",
    "\t\tself.bert.load_state_dict(checkpoint['bert'])\n",
    "\t\tself.tokenizer = AutoTokenizer.from_pretrained(model_path.replace('bert_hybrid.pth', 'tokenizer.pth'))\n",
    "\t\tself.nn_layers.load_state_dict(checkpoint['nn_layers'])\n",
    "\t\tself.final_layers.load_state_dict(checkpoint['final_layers'])\n",
    "\t\tself.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\t\tself.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\t\tself.criterion.load_state_dict(checkpoint['criterion'])\n",
    "\t\tself.to(self.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model and apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertClassifier()\n",
    "\n",
    "# input_ids, attention_masks, nn_inputs, outputs = model.load_data_tensors(which='train')\n",
    "# train_dataloader = model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, RandomSampler)\n",
    "\n",
    "# input_ids, attention_masks, nn_inputs, outputs = model.load_data_tensors(which='val')\n",
    "# val_dataloader = model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, SequentialSampler)\n",
    "\n",
    "# GPUs = GPUtil.getGPUs()\n",
    "# if GPUs:\n",
    "#     gpu = GPUs[0]\n",
    "#     print(f\"Training model on: {gpu.name}\")\n",
    "# else:\n",
    "#     print(\"Training model on CPU\")\n",
    "    \n",
    "# train_losses, val_losses, train_accuracies, val_accuracies = model.train_model(train_dataloader, val_dataloader, email_updates=True)\n",
    "\n",
    "# print(\"Train losses: \", train_losses)\n",
    "# print(\"Val losses: \", val_losses)\n",
    "# print(\"Train accuracies: \", train_accuracies)\n",
    "# print(\"Val accuracies: \", val_accuracies)\n",
    "\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.legend()\n",
    "# title = \"Losses Of Train and Validation\"\n",
    "# file_name = title.replace(\" \", \"_\").lower()\n",
    "# plt.title(title)\n",
    "# plt.savefig(f'{os.path.join(config.output_folder, file_name)}')\n",
    "# plt.show()\n",
    "# plt.clf()\n",
    "\n",
    "\n",
    "# plt.plot(train_accuracies, label='Training Acc')\n",
    "# plt.plot(val_accuracies, label='Validation Acc')\n",
    "# plt.legend()\n",
    "# title = \"Accs Of Train and Validation\"\n",
    "# file_name = title.replace(\" \", \"_\").lower()\n",
    "# plt.title(title)\n",
    "# plt.savefig(f'{os.path.join(config.output_folder, file_name)}')\n",
    "# plt.show()\n",
    "\n",
    "# save_path, tokenizer_save_path = model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment in/out to either use or not use this model\n",
    "# save_path = 'outputs/part2model2_output_16/bert_hybrid.pth'\n",
    "\n",
    "\n",
    "# loaded_model = BertClassifier(load_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids, attention_masks, nn_inputs, outputs = loaded_model.load_data_tensors(which='test')\n",
    "\n",
    "# test_dataloader = loaded_model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, SequentialSampler)\n",
    "\n",
    "# print(loaded_model.evaluate(test_dataloader))\n",
    "\n",
    "# pred, labels = loaded_model.predict(test_dataloader)\n",
    "\n",
    "# print(np.hstack((pred, labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_strings, nn_inputs, outputs = loaded_model.load_strings_data_tensors(which='test')\n",
    "\n",
    "\n",
    "# test_dataloader = loaded_model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, SequentialSampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_input = nn_inputs[0].view(1, -1).to(loaded_model.device)\n",
    "# loaded_model.predict_single(padded_strings[0], nn_input, sigmoid=True)\n",
    "# print(\"Correct input dims. Text: \", len(padded_strings[0]), \"NN input: \", nn_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = np.array(padded_strings, dtype=object)\n",
    "# nn_samples = nn_inputs.numpy()\n",
    "\n",
    "# combined_samples = np.hstack((texts.reshape(-1, 1), nn_samples))\n",
    "\n",
    "# combined_samples.shape\n",
    "\n",
    "# print(\"Creating shap explainer... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.KernelExplainer(loaded_model.new_predict_multiple_output_shap, \n",
    "#                                  data=combined_samples[:20])\n",
    "\n",
    "# # explainer = shap.KernelExplainer(loaded_model.new_predict_multiple_output_shap, \n",
    "# #                                  data=combined_samples[:20],\n",
    "# #                                  masker=shap.maskers.Text(tokenizer=loaded_model.tokenizer, mask_token='[MASK]', collapse_mask_token=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating the shap values for the first 20 inputs\n",
    "\n",
    "# print(\"Calculating shap values...\")\n",
    "# shap_values = explainer(combined_samples[:20])\n",
    "\n",
    "# # Save the shap values for later\n",
    "# shap_values_path = utils.get_next_filename(os.path.join(config.output_folder, 'shap_values.pkl'))\n",
    "# shap_values_path = \"outputs/part2model2_output_23/shap_values_0.pkl\"\n",
    "# with open(shap_values_path, 'wb') as f:\n",
    "#     pickle.dump(shap_values, f)\n",
    "# print(f\"Shap values saved to {shap_values_path}\")\n",
    "\n",
    "# utils.send_email(f\"✅ SHAP Values saved {config.filename} execution\", f\"Took {utils.get_time_from_start(start_time)}\\nConfig: {config.__dict__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values_path = \"outputs/part2model2_output_23/shap_values_0.pkl\"\n",
    "# with open(shap_values_path, \"rb\") as f:\n",
    "#     shap_values = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot and save the bar plot\n",
    "# plt.clf()\n",
    "# shap.summary_plot(shap_values)\n",
    "# file_name = 'summary_plot.png'\n",
    "# plt.savefig(f'{os.path.join(config.output_folder, file_name)}')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot and save the bar plot\n",
    "# plt.clf()\n",
    "# shap.plots.bar(shap_values, max_display=23)\n",
    "# file_name = 'shap_bar_plot.png'\n",
    "# plt.savefig(f'{os.path.join(config.output_folder, file_name)}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.send_email(f\"✅ Finished {config.filename} execution\", f\"Took {utils.get_time_from_start(start_time)}\\nConfig: {config.__dict__}\")\n",
    "\n",
    "# save the config's state dict as a file\n",
    "with open(os.path.join(config.output_folder, 'config.json'), 'w') as f:\n",
    "    json.dump(config.__dict__, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchviz\n",
    "\n",
    "# # Move tensors to the same device as the model\n",
    "# device = loaded_model.device\n",
    "# input_ids = test_dataloader.dataset.tensors[0][0].view(1, -1).to(device)\n",
    "# attention_mask = test_dataloader.dataset.tensors[1][0].view(1, -1).to(device)\n",
    "# nn_input = test_dataloader.dataset.tensors[2][0].view(1, -1).to(device)\n",
    "\n",
    "# # Forward pass\n",
    "# y = loaded_model.forward(input_ids, attention_mask, nn_input)\n",
    "\n",
    "# # Visualize the model\n",
    "# dot = torchviz.make_dot(y, params=dict(loaded_model.named_parameters()))\n",
    "# dot.render(\"model_graph\", format=\"png\", cleanup=True)  # Save as PNG\n",
    "# dot  # Display graph\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# loaded_model\n",
    "# writer = SummaryWriter()\n",
    "# dummy_input = [input_ids, attention_mask, nn_input]\n",
    "# writer.add_graph(loaded_model, dummy_input)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.24827288e-01, -1.23642408e-04,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.48688542e-02, -7.71855773e-05,\n",
       "        -2.95595568e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "        -7.34702722e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.50000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.24988644e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.13680514e-04,  2.49298035e-02,  0.00000000e+00,\n",
       "         2.08504904e-04,  0.00000000e+00, -3.20434262e-04,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.78690886e-04,  1.64797401e-04,\n",
       "         0.00000000e+00,  1.93694851e-04,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])\n",
       "\n",
       ".base_values =\n",
       "array([0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55,\n",
       "       0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55])\n",
       "\n",
       ".data =\n",
       "array([[\"It's a great store for wine, Spirits, Cigars and so much more and they have the best prices anywhere! Believe me I have been all over and they can beat anyone's prices and they have a great app for Rewards that I use always and have received many Free things from the app! Enjoy  Unfortunately they are low on their cigar selection due to Covid Plandemic!\",\n",
       "        38.626182556152344, -90.3412094116211, 4.0, 71.0,\n",
       "        4.2253522872924805, 5.199999809265137, 0.2984909415245056, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "        0.0, 0.0],\n",
       "       [\"Probably the best nail salon in Tucson. Definitely the cleanest and they focus on being very sanitary. Tony and Nina are super friendly and Tony is hilarious. Nina does a great job massaging your legs, far longer then I've ever had done. Prices are lower then most places, this is the only nail salon I will go to.\",\n",
       "        32.207733154296875, -110.8382339477539, 4.0, 67.0,\n",
       "        5.970149040222168, 0.0, 0.22746460139751434, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [\"This Taco Bell occasionally has decent service, but besides that it is without a doubt the WORST Taco Bell I have ever been to, which is a shame since it is so close to my house. Every Crunchwrap I get is uneven and disgusting, their freezes come half melted, and my food usually comes cold and gross. To top it all off, they are commonly out of stock of the most basic items. You're out of shredded cheese, shredded chicken, half the drinks on your menu, and like 6 more items on top of that? Besides the very cool guy who is usually in the drive through, this Taco Bell is disgusting and needs new management immediately. It's an embarrassment\",\n",
       "        27.80484962463379, -82.63878631591797, 2.0, 41.0,\n",
       "        2.4390244483947754, 8.588889122009277, 0.5643751621246338, 0.0,\n",
       "        1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0],\n",
       "       [\"I used UberEATS to deliver their food and I must say, outside of a Thai Temple when they have festivals, I haven't had this good of Thai food! The Tom Kha Kai was very tasty with just the right balance of ginger and lemon grass. I'm normally not a fan of Pad Thai because I've had bad experiences but theirs - YUM! I request a specific heat/spicy level and they NAILED IT. I will order from them again and SOON\",\n",
       "        29.952102661132812, -90.07206726074219, 3.0, 152.0,\n",
       "        1.9736841917037964, 1.4444444179534912, 0.23013462126255035, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0],\n",
       "       [\"Ugh. We spent almost $350. Why are people raving about this? There were 2 out of 12 dishes that had some flavor. The best part of the entire experience was the wait staff and the beverage paring. DO NOT WASTE YOUR MONEY. I am sorry to have to be bearer of bad news but it's not good. Don't do it.\",\n",
       "        38.61067199707031, -90.2240219116211, 4.5, 74.0, 0.0, 0.0,\n",
       "        0.29824644327163696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       "       ['i love the  store in Tampa , I always go back , a little disorganized but not big deal.',\n",
       "        27.903032302856445, -82.50544738769531, 3.5, 74.0,\n",
       "        4.054054260253906, 1.4444444179534912, 0.5849634408950806, 0.0,\n",
       "        1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0],\n",
       "       [\"Words can not express how amazing my experience has been with Amber Light Voice Studios. I started my journey skeptical because I didn't know what to expect. I have spent a lot of time neglecting to learn technique and finding the courage to be an ACTUAL singer. I had always thought being a singer isn't practical when deep down it was always my insecurities with my voice. It's been almost a year since I have been taking classes at Amber Light Studios and the improvement I have seen is more than I could ask for. I started with Ben, but had to take a brief hiatus. I could tell after a few classes with him I was going to be the singer I wanted to be. My primary teacher for most of my journey has been Cait, she is awesome!! The best teacher I've had in any subject. So kind, so relatable and knowledgeable. Since joining Amber Light I have progressed tremendously with their very consistent training method and even found the courage to audition for the Herb Alpert Music Academy which now I have a full ride through their program. It's all thanks to the team at Amber Light Studios. I have no plans on stopping my training at their school while I study full time. There's no better price out here for their contemporary with a touch of classical styled curriculum which is combined with the music I want to learn how to sing. I am so thankful to  Cait, Ben, Andrea and the rest of Amber Light Studios staff for helping me learn how to use my voice.\",\n",
       "        36.20518112182617, -86.7201919555664, 5.0, 38.0,\n",
       "        2.6315789222717285, 0.0, 0.271831750869751, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [\"Haven't eaten here for quite some time.  Service was mediocre at best.  Prices in my opinion a little high.  Biggest complaint is that we are in the restaurant and just handed our pita.  Asked for a plate and was told that how you get when you eat in house.   Seriously provide a basket or a plate.  Don't want to put my food on the table.  Won't be back.\",\n",
       "        43.590763092041016, -116.35649871826172, 2.5, 34.0, 0.0,\n",
       "        5.433333396911621, 0.1034681648015976, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [\"I wish I could provide a lower rating. $22 for a delivery fee is completely unnecessary. I was recently charged the same amount of gas this month as I was for the previous month even though I was gone half the month and barely used my gas-eating appliances. I tried calling the company to find out what was happening with my bill and got hung up after waiting on the phone nearly every time I called.\\n\\nI'm unhappy with prices now, and, after reading other reviews, very nervous about the upcoming winter season. \\n\\nThe city of St. Louis needs to bring in some competition and stop this price gouging ASAP.\",\n",
       "        38.62582778930664, -90.19285583496094, 1.0, 48.0, 6.25, 0.0,\n",
       "        0.29806241393089294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       "       ['Hooray this place has new owners and a new face. And even better the food quality has seriously improved ! Great local dinner and cafe for the area. The new owners are super friendly and staff is too what a change for the better. And from what we are told soon to be an addition of a bakery . Looking forward to everything about this change .',\n",
       "        28.092063903808594, -82.57855987548828, 3.5, 55.0,\n",
       "        5.454545497894287, 0.0, 0.5786514282226562, 0.0, 1.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       ['THis place has a nice atmosphere to it. Really casual.\\n\\nThey don\\'t serve food but like WOB you can order or bring in food from the neighboring spots like mexican or sushi.We like to order a little from both and mix them up with beers to have our own \"international night\"\\n\\nWHen it\\'s dead, it\\'s dead, quiet, too much so. Bring friends and hit it on a Fri or Sat ngiht it\\'s a lot more fun then!',\n",
       "        27.773975372314453, -82.63372039794922, 4.5, 217.0,\n",
       "        1.382488489151001, 0.0, 0.5554177165031433, 0.0, 1.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       ['I visit this Starbucks often. During busy hours I do anticipate a longer wait time and unfortunately can be waiting for up to 15 minutes. However, I find the customer service here to be wonderful. I stopped in later in the evening recently and the drive through attendant asked me at the window what my plans were for the evening. I told him I was heading back to the hospital after a long day there already. He told me he was very sorry if I had anyone close to me in the hospital and gave me an extra shot of espresso to get me through the night. Very kind gesture and was nice to have conversation with him!',\n",
       "        39.95238494873047, -86.16291809082031, 3.5, 29.0,\n",
       "        3.4482758045196533, 9.386666297912598, 0.25072070956230164, 0.0,\n",
       "        0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0],\n",
       "       [\"We've been here several times and the food and service has been exceptional every time! Today we had Griffin- best service I've EVER had.\",\n",
       "        36.210044860839844, -86.92381286621094, 4.0, 136.0,\n",
       "        4.411764621734619, 0.0, 0.27036142349243164, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [\"Cozy little spot with excellent ramen. Host very attentive. Food was very delicious! Can't wait to be back!\",\n",
       "        39.90308380126953, -74.97147369384766, 4.5, 184.0,\n",
       "        2.17391300201416, 0.0, 0.9773010611534119, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [\"What a grand hotel! From the minute we pulled in to the minute we left, everything was spot-on perfect.\\n\\nCheck-in was incredibly smooth, and everyone from the valet to the concierge to the front desk staff was helpful, cheerful, and personable. \\n\\nOur room was AMAZING. We had a fantastic view of the park because of massive windows. The king-sized bed was so comfortable we didn't wake up once. Our room (suite?) was so spacious, and I loved that there was a vanity area right outside the bathroom so I could get ready while the fella showered. Speaking of the shower, it was awesome; most stand-up showers barely have enough room to turn around, but this one might've been bigger than my entire house. The toiletries and water pressure were great, and it came with a hair dryer (hooray) and a scale (boo hiss).\\n\\nThe staff gave us a complimentary fruit bowl and offered turn down service. We also had a card under our door in the morning with the weather forecast. Last but not least, free wifi!\\n\\nThe location couldn't be better and more central for what we wanted to do (LOVE park, art museum, Independence Hall, Liberty Bell), and it was easy to walk places or catch a cab to/from the hotel.\",\n",
       "        39.949913024902344, -75.17364501953125, 4.0, 125.0,\n",
       "        3.200000047683716, 0.0, 0.9957838654518127, 1.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [\"Oh what a night. This place was awesome, not to mention the bull ride was super fun. Aight it wasn't that much fun. It was kind of slow actually, in comparison to another bull I've rode. Other than that, the vibe was really nice. A little run down, the bathroom was falling apart but clean, and the stairs were quite sketchy. But overall a very good and old fashion fun type place. Could have been more fun but social media had restricted me from partaking in many a shenanigan.\",\n",
       "        29.955493927001953, -90.06863403320312, 3.0, 187.0,\n",
       "        0.5347593426704407, 0.0, 0.23013275861740112, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       ['They improved the atmosphere and revamped the entire inside! The food has always been, and is still delicious!  I have come here for years with my family and friends. The bartenders and servers are attentive and wonderful! Go check out the upgrades!!!!',\n",
       "        40.23491668701172, -74.94025421142578, 4.0, 55.0,\n",
       "        3.6363637447357178, 0.0, 0.9082048535346985, 1.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       ['BS.  Went in and asked a simple question about how to get a tool to solve a problem involving unlocking a hub nut.  Was told \"you can\\'t do it yourself\" and \"you can\\'t get that tool\"\\n\\nIf was a weak effort make them look like the \"go to\" for the job.  So for fun, I got a quote on what it would run:  $800 to replace two half axles.  The parts are $75 each so this amount of labor seems unreasonable to me.  \\n\\nThe guy who quoted me was nice enough, but it was very clear that he wanted to offer no assistance since I was obviously a \"DIY-er\".  \\n\\nI\\'ll tell you--there are plenty of things I will not do on my vehicles, but I will most certainly not have them done at this shop as a result of the apathetic attitude that I was shown.\\n\\nEven when asked \"where can I the tool I need\"--he said \"YOU CANT\"  That\\'s all, no simple solution which I know there are.  So now I will order the part online that I need and make sure to never, ever go to this place again.\\n\\nWord of advice from a business owner--help anyone who asks--even if you\\'re not going to make money at that time because they will send referrals and come back when they do need help.',\n",
       "        32.307960510253906, -110.89029693603516, 2.5, 31.0, 0.0,\n",
       "        8.042222023010254, 0.22701938450336456, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       ['My go to place to feel better is Ralston. They have easy to book appointments through their website and offer many different types of massages with a wide range of days and times. What I love is that they focus on your problem areas to make you better. Prices are reasonable and the massages are amazing. I always go in with serious pains in my neck and shoulder area and always leave feeling like I am on cloud 9. If you need a massage, Ralston is the place to go. The people are also amazing, friendly, helpful, knowledgeable, and welcoming.',\n",
       "        39.504920959472656, -119.80328369140625, 4.5, 39.0,\n",
       "        2.5641026496887207, 0.0, 0.17901894450187683, 0.0, 0.0, 0.0, 0.0,\n",
       "        1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       ['The best Chinese food in Tucson, Crab Puffs, Spare ribs, Dumplings and Wor Wanton were great, the mains sesame chicken, Mongolian beef and pork fried rice were excellent! We drove from Green Valley which is a one way 40 mile trip and it was worth it!',\n",
       "        32.20753860473633, -110.7911605834961, 4.5, 258.0,\n",
       "        2.7131783962249756, 1.8888888359069824, 0.22694730758666992, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
