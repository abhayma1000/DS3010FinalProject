{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Load in the tensors and configuration from Config class and yeah. Build the bert model locally and have an option to load in another pre-trained one\n",
    "\n",
    "Features\n",
    "\n",
    "* Initialize from scratch\n",
    "* Initialize from pre-trained model\n",
    "* Set freezable parameters\n",
    "Load in tensor data\n",
    "* Create data loaders\n",
    "* Predict function(nn inputs and input_ids/attention mask)\n",
    "* Predict function(nn inputs and text)\n",
    "* Evaluation function(some data loader)\n",
    "* Train one epoch\n",
    "* Train multiple epochs\n",
    "    * Calls train one epoch but has more overall reporting stats, perhaps return history object\n",
    "* Save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import constants\n",
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'part2model2testconfigs'\n",
    "output_folder, num = utils.get_next_output_folder(f'outputs/{filename}_output')\n",
    "config = constants.Config(filename,\n",
    "                          output_folder = output_folder,\n",
    "                          num_iteration=num,\n",
    "                          epochs=5,\n",
    "                          load_tensor_path='outputs/part2preprocessing_output_8',\n",
    "                          )\n",
    "print(\"Output folder: \", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, get_linear_schedule_with_warmup, BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.display import display, clear_output\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import GPUtil\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('stopwords')\n",
    "try:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nltk.download('averaged_perceptron_tagger_eng')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "os.system('./venv/bin/python -m spacy download en_core_web_sm')\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nltk.download('punkt_tab')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\tdef __init__(self, \n",
    "\t\t\t\t load_path=config.load_in_model_path, \n",
    "\t\t\t\t batch_size=config.batch_size, \n",
    "\t\t\t\t epochs=config.epochs, \n",
    "\t\t\t\t tokenizer_max_length=config.tokenizer_max_length, \n",
    "\t\t\t\t nn_input_size=config.nn_input_size):\n",
    "\t\t\n",
    "\t\tsuper(BertClassifier, self).__init__()\n",
    "\t\t\n",
    "\t\tself.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\t\tprint(\"Running on device: \", self.device)\n",
    "\n",
    "\t\tprint(\"Constructing model...\")\n",
    "\t\tself.bert = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
    "\t\tself.bert_output_size = self.bert.config.hidden_size\n",
    "\n",
    "\t\tself.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\t\tself.nn_output_size = 12\n",
    "\t\tself.nn_layers = nn.Sequential(\n",
    "\t\t\tnn.Linear(nn_input_size, 12),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(12, self.nn_output_size),\n",
    "\t\t\tnn.ReLU()\n",
    "\t\t).to(self.device)\n",
    "\n",
    "\t\tself.final_layers = nn.Sequential(\n",
    "\t\t\tnn.Linear(self.bert_output_size + self.nn_output_size, 12),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(12, 1)\n",
    "\t\t).to(self.device)\n",
    "\n",
    "\t\tself.optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5, eps=1e-8)\n",
    "\t\tself.scheduler = self.get_scheduler(self.optimizer, None)\n",
    "\t\tself.criterion = nn.BCEWithLogitsLoss()\n",
    "\t\t\t\n",
    "\t\tif load_path:\n",
    "\t\t\tprint(\"Loading in model...\")\n",
    "\t\t\tself.load_model(load_path)\n",
    "\n",
    "\t\tself.batch_size=batch_size\n",
    "\t\tself.epochs = epochs\n",
    "\t\tself.tokenizer_max_length = tokenizer_max_length\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "\tdef forward(self, input_ids, attention_mask, nn_input):\n",
    "\t\tbert_outputs = self.bert(input_ids, attention_mask)\n",
    "\t\tpooled_output = bert_outputs.pooler_output\n",
    "\n",
    "\t\tnn_outputs = self.nn_layers(nn_input)\n",
    "\t\tfinal_input = torch.cat((pooled_output, nn_outputs), dim=1)\n",
    "\t\treturn self.final_layers(final_input)\n",
    "\n",
    "\n",
    "\n",
    "\tdef train_model(self, train_dataloader: DataLoader,\n",
    "\t\t   val_dataloader: DataLoader):\n",
    "\t\tprint(\"Training model...\")\n",
    "\n",
    "\t\ttrain_losses = []\n",
    "\t\tval_losses = []\n",
    "\t\ttrain_accuracies = []\n",
    "\t\tval_accuracies = []\n",
    "\n",
    "\t\tbest_val_acc = 0.0\n",
    "\n",
    "\t\t# Set these when training\n",
    "\t\tself.optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5, eps=1e-8)\n",
    "\t\tself.scheduler = self.get_scheduler(self.optimizer, train_dataloader)\n",
    "\t\tself.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\t\tfor epoch in range(self.epochs):\n",
    "\t\t\tprint(f\"\\n===== Epoch {epoch + 1}/{self.epochs} =====\")\n",
    "\n",
    "\t\t\ttrain_loss, train_acc = self.train_epoch(train_dataloader)\n",
    "\t\t\ttrain_losses.append(train_loss)\n",
    "\t\t\ttrain_accuracies.append(train_acc)\n",
    "\n",
    "\t\t\tval_loss, val_acc = self.evaluate(val_dataloader, epoch)\n",
    "\t\t\tval_losses.append(val_loss)\n",
    "\t\t\tval_accuracies.append(val_acc)\n",
    "\n",
    "\t\t\tif val_acc > best_val_acc:\n",
    "\t\t\t\tbest_val_acc = val_acc\n",
    "\t\t\t\tself.save_model()\n",
    "\t\t\n",
    "\t\treturn train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "\t\n",
    "\tdef train_epoch(self, train_dataloader: DataLoader):\n",
    "\t\tself.train()\n",
    "\n",
    "\t\ttrain_loss = 0\n",
    "\t\tcorrect_predictions = 0\n",
    "\t\ttotal_samples = 0\n",
    "\n",
    "\t\tfor step, batch in enumerate(train_dataloader):\n",
    "\t\t\tprint(f\"Progress: {step + 1}/{len(train_dataloader)}\", end='\\r')\n",
    "\n",
    "\t\t\tself.optimizer.zero_grad()\n",
    "\n",
    "\t\t\tb_input_ids = batch[0].to(self.device)\n",
    "\t\t\tb_input_mask = batch[1].to(self.device)\n",
    "\t\t\tb_nn_input = batch[2].to(self.device)\n",
    "\t\t\tb_labels = batch[3].to(self.device)\n",
    "\n",
    "\t\t\tb_labels = b_labels.float().view(-1, 1)\n",
    "\n",
    "\t\t\toutput = self.forward(b_input_ids, b_input_mask, b_nn_input)\n",
    "\t\t\tloss = self.criterion(output, b_labels)\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\t\t\tself.scheduler.step()\n",
    "\n",
    "\t\t\ttrain_loss += loss.item()\n",
    "\n",
    "\t\t\tpreds = torch.round(torch.sigmoid(output))\n",
    "\n",
    "\t\t\tcorrect_predictions += torch.sum(preds == b_labels)\n",
    "\t\t\ttotal_samples += b_labels.size(0)\n",
    "\t\t\n",
    "\t\ttrain_loss /= len(train_dataloader)\n",
    "\t\ttrain_acc = (correct_predictions / total_samples).item()\n",
    "\n",
    "\t\tprint(\"Training Loss: \", train_loss)\n",
    "\t\tprint(\"Train accuracy: \", train_acc)\n",
    "\t\treturn train_loss, train_acc,\n",
    "\n",
    "\t\n",
    "\tdef predict(self, test_dataloader: DataLoader):\n",
    "\t\tself.eval()\n",
    "\n",
    "\t\tall_preds = []\n",
    "\t\tall_labels = []\n",
    "\n",
    "\t\tfor step, batch in enumerate(test_dataloader):\n",
    "\t\t\tprint(f\"Progress: {step + 1}/{len(test_dataloader)}\", end='\\r')\n",
    "\n",
    "\t\t\tb_input_ids = batch[0].to(self.device)\n",
    "\t\t\tb_input_mask = batch[1].to(self.device)\n",
    "\t\t\tb_nn_input = batch[2].to(self.device)\n",
    "\t\t\tb_labels = batch[3].to(self.device)\n",
    "\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\toutput = self.forward(b_input_ids, b_input_mask, b_nn_input)\n",
    "\t\t\t\tpreds = torch.round(torch.sigmoid(output))\n",
    "\n",
    "\t\t\t\tall_preds.extend(preds.cpu().numpy())\n",
    "\t\t\t\tall_labels.extend(b_labels.cpu().numpy())\n",
    "\t\t\n",
    "\t\treturn np.array(all_preds), np.array(all_labels).reshape(-1, 1)\n",
    "\n",
    "\tdef predict_single(self, text: str, nn_input: torch.Tensor):\n",
    "\t\tself.eval()\n",
    "\n",
    "\t\tencoded_text = self.tokenizer.encode_plus(\n",
    "\t\t\ttext,\n",
    "\t\t\tadd_special_tokens=True,\n",
    "\t\t\tpadding='max_length',\n",
    "\t\t\tmax_length=config.tokenizer_max_length,\n",
    "\t\t\tpad_to_max_length=True,\n",
    "\t\t\treturn_attention_mask=True,\n",
    "\t\t\treturn_tensors='pt',\n",
    "\t\t\ttruncation=True\n",
    "\t\t)\n",
    "\n",
    "\t\tinput_ids = encoded_text['input_ids'].to(self.device)\n",
    "\t\tattention_mask = encoded_text['attention_mask'].to(self.device)\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutput = self.forward(input_ids, attention_mask, nn_input)\n",
    "\t\t\tpred = torch.round(torch.sigmoid(output))\n",
    "\n",
    "\t\treturn pred.item()\n",
    "\n",
    "\n",
    "\tdef evaluate(self, test_dataloader: DataLoader, epoch=None):\n",
    "\t\tself.eval()\n",
    "\t\t\n",
    "\t\tpreds, labels = self.predict(test_dataloader)\n",
    "\t\tpreds = np.array(preds)\n",
    "\t\tlabels = np.array(labels)\n",
    "\t\tprint(\"Classification Report\" + (f\" Epoch {epoch}\" if epoch else \"\") + \":\")\n",
    "\t\tprint(classification_report(labels, preds))\n",
    "\t\tprint(\"Number of examples: \", len(labels))\n",
    "\t\tprint(\"Number of correct predictions: \", (preds == labels).sum())\n",
    "\n",
    "\t\tpreds_tensor, labels_tensor = torch.tensor(preds), torch.tensor(labels)\n",
    "\t\tnum_classes = 2\n",
    "\t\tprint(\"Accuracy: \", torchmetrics.functional.accuracy(preds_tensor, labels_tensor, num_classes=num_classes, task='binary').item())\n",
    "\t\tprint(\"Macro F1 score: \", f1_score(preds_tensor, labels_tensor, num_classes=num_classes, average='macro', task='binary').item())\n",
    "\t\tprint(\"Micro F1 score: \", f1_score(preds_tensor, labels_tensor, num_classes=num_classes, average='micro', task='binary').item())\n",
    "\t\tprint(\"Weighted F1 score: \", f1_score(preds_tensor, labels_tensor, num_classes=num_classes, average='weighted', task='binary').item())\n",
    "\n",
    "\n",
    "\n",
    "\t\tloss = self.criterion(torch.tensor(preds).view(-1, 1), torch.tensor(labels).view(-1, 1)).item()\n",
    "\n",
    "\t\tacc = (preds == labels).mean().item()\n",
    "\n",
    "\t\tprint(\"Accuracy: \", acc)\n",
    "\t\tprint(\"Loss: \", loss)\n",
    "\n",
    "\t\treturn loss, acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tdef load_data_tensors(self, which='train', tensor_path=config.load_tensor_path):\n",
    "\t\ttensors = torch.load(os.path.join(tensor_path, f'all_tensors_percentage_1_{which}.pth'))\n",
    "\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tprint(f\"Loading in tensors from {which} dataset...\")\n",
    "\t\tprint(\"Number of samples: \", len(tensors['input_ids']))\n",
    "\t\tprint(\"Dims of input_ids: \", tensors['input_ids'].shape)\n",
    "\t\tprint(\"Dims of attention_masks: \", tensors['attention_masks'].shape)\n",
    "\t\tprint(\"Dims of nn_inputs: \", tensors['nn_inputs'].shape)\n",
    "\t\tprint(\"Dims of outputs: \", tensors['outputs'].shape)\n",
    "\t\t\n",
    "\t\treturn tensors['input_ids'], tensors['attention_masks'], tensors['nn_inputs'], tensors['outputs']\n",
    "\n",
    "\tdef create_dataloaders(self, \n",
    "\t\t\t\t\t\tinput_ids: torch.Tensor,\n",
    "\t\t\t\t\t\tattention_masks: torch.Tensor,\n",
    "\t\t\t\t\t\tnn_inputs: torch.Tensor,\n",
    "\t\t\t\t\t\toutputs: torch.Tensor,\n",
    "\t\t\t\t\t\tsampler: SequentialSampler):\n",
    "\t\n",
    "\t\tdataset = TensorDataset(input_ids, attention_masks, nn_inputs, outputs)\n",
    "\n",
    "\t\tprint(\"Creating dataloaders...\")\n",
    "\t\tprint(\"Number of samples: \", len(dataset))\n",
    "\n",
    "\t\tdataloader = DataLoader(\n",
    "\t\t\tdataset,\n",
    "\t\t\tsampler=sampler(dataset),\n",
    "\t\t\tbatch_size=self.batch_size\n",
    "\t\t)\n",
    "\n",
    "\t\treturn dataloader\n",
    "\t\n",
    "\tdef get_scheduler(self, optimizer, train_dataloader=None):\n",
    "\t\tif train_dataloader is None:\n",
    "\t\t\ttotal_steps=100000\n",
    "\t\telse:\n",
    "\t\t\ttotal_steps = len(train_dataloader) * self.epochs\n",
    "\t\tscheduler = get_linear_schedule_with_warmup(\n",
    "\t\t\toptimizer,\n",
    "\t\t\tnum_warmup_steps=0,\n",
    "\t\t\tnum_training_steps=total_steps\n",
    "\t\t)\n",
    "\t\treturn scheduler\n",
    "\n",
    "\t\n",
    "\tdef freeze_layers(self, num_layers_left_unfrozen: int):\n",
    "\t\tfor param in self.bert.parameters():\n",
    "\t\t\tparam.requires_grad = False\n",
    "\t\t\n",
    "\t\tfor param in self.bert.encoder.layer[num_layers_left_unfrozen:].parameters():\n",
    "\t\t\tparam.requires_grad = True\n",
    "\t\t\n",
    "\t\n",
    "\t\t\n",
    "\n",
    "\tdef save_model(self, output_folder=config.output_folder):\n",
    "\t\tsave_path = os.path.join(output_folder, 'bert_hybrid.pth')\n",
    "\t\ttokenizer_save_path = os.path.join(output_folder, 'tokenizer.pth')\n",
    "\t\ttorch.save({\n",
    "\t\t\t'bert': self.bert.state_dict(),\n",
    "\t\t\t'nn_layers': self.nn_layers.state_dict(),\n",
    "\t\t\t'final_layers': self.final_layers.state_dict(),\n",
    "\t\t\t'optimizer': self.optimizer.state_dict(),\n",
    "\t\t\t'scheduler': self.scheduler.state_dict(),\n",
    "\t\t\t'criterion': self.criterion.state_dict()\n",
    "\t\t}, save_path)\n",
    "\n",
    "\t\tself.tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\t\tprint(\"Model saved to: \", save_path)\n",
    "\t\tprint(\"Tokenizer saved to: \", tokenizer_save_path)\n",
    "\n",
    "\t\treturn save_path, tokenizer_save_path\n",
    "\n",
    "\n",
    "\n",
    "\tdef load_model(self, model_path=config.load_in_model_path):\n",
    "\t\tprint(\"Loading in model from : \", model_path)\n",
    "\t\ttry:\n",
    "\t\t\tcheckpoint = torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\t\texcept:\n",
    "\t\t\twith open(model_path, \"rb\") as f:\n",
    "\t\t\t\tbuffer = io.BytesIO(f.read())\n",
    "\n",
    "\t\t\tcheckpoint = torch.load(buffer, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\t\tprint(\"Successfully loaded big tensor...\")\n",
    "\t\tself.bert.load_state_dict(checkpoint['bert'])\n",
    "\t\tself.tokenizer = AutoTokenizer.from_pretrained(model_path.replace('bert_hybrid.pth', 'tokenizer.pth'))\n",
    "\t\tself.nn_layers.load_state_dict(checkpoint['nn_layers'])\n",
    "\t\tself.final_layers.load_state_dict(checkpoint['final_layers'])\n",
    "\t\tself.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\t\tself.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\t\tself.criterion.load_state_dict(checkpoint['criterion'])\n",
    "\t\tself.to(self.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model and apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier()\n",
    "\n",
    "input_ids, attention_masks, nn_inputs, outputs = model.load_data_tensors(which='train')\n",
    "train_dataloader = model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, RandomSampler)\n",
    "\n",
    "input_ids, attention_masks, nn_inputs, outputs = model.load_data_tensors(which='val')\n",
    "val_dataloader = model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, SequentialSampler)\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "if GPUs:\n",
    "    gpu = GPUs[0]\n",
    "    print(f\"Training model on: {gpu.name}\")\n",
    "else:\n",
    "    print(\"Training model on CPU\")\n",
    "    \n",
    "train_losses, val_losses, train_accuracies, val_accuracies = model.train_model(train_dataloader, val_dataloader)\n",
    "\n",
    "print(\"Train losses: \", train_losses)\n",
    "print(\"Val losses: \", val_losses)\n",
    "print(\"Train accuracies: \", train_accuracies)\n",
    "print(\"Val accuracies: \", val_accuracies)\n",
    "\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "title = \"Losses Of Train and Validation\"\n",
    "file_name = title.replace(\" \", \"_\").lower()\n",
    "plt.title(title)\n",
    "plt.savefig(f'{os.path.join(config.output_folder, file_name)}')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.plot(train_accuracies, label='Training Acc')\n",
    "plt.plot(val_accuracies, label='Validation Acc')\n",
    "plt.legend()\n",
    "title = \"Accs Of Train and Validation\"\n",
    "file_name = title.replace(\" \", \"_\").lower()\n",
    "plt.title(title)\n",
    "plt.savefig(f'{os.path.join(config.output_folder, file_name)}')\n",
    "plt.show()\n",
    "\n",
    "save_path, tokenizer_save_path = model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment in/out to either use or not use this model\n",
    "save_path = 'outputs/part2model2_output_16/bert_hybrid.pth'\n",
    "\n",
    "\n",
    "loaded_model = BertClassifier(load_path=save_path)\n",
    "\n",
    "input_ids, attention_masks, nn_inputs, outputs = loaded_model.load_data_tensors(which='test')\n",
    "\n",
    "test_dataloader = loaded_model.create_dataloaders(input_ids, attention_masks, nn_inputs, outputs, SequentialSampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.evaluate(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, labels = loaded_model.predict(test_dataloader)\n",
    "\n",
    "print(np.hstack((pred, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([])\n",
    "# text = \"Very nice staff, and the airport shuttle runs 24 hours a day which is convenient. The shuttle will also take you to places within a couple of miles of the hotel, so you can eat, shop, or go bar hopping and not have to call a cab! Next door is a very good looking Cuban breakfast/lunch spot which closes at 3pm. Will need to try that on my next visit.\"\n",
    "# loaded_model.predict_single(text, torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]).view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.send_email(f\"âœ… Finished {config.filename} execution\", f\"Took {utils.get_time_from_start(start_time)}\\nConfig: {config.__dict__}\")\n",
    "\n",
    "# save the config's state dict as a file\n",
    "with open(os.path.join(config.output_folder, 'config.json'), 'w') as f:\n",
    "    json.dump(config.__dict__, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchviz\n",
    "\n",
    "# # Move tensors to the same device as the model\n",
    "# device = loaded_model.device\n",
    "# input_ids = test_dataloader.dataset.tensors[0][0].view(1, -1).to(device)\n",
    "# attention_mask = test_dataloader.dataset.tensors[1][0].view(1, -1).to(device)\n",
    "# nn_input = test_dataloader.dataset.tensors[2][0].view(1, -1).to(device)\n",
    "\n",
    "# # Forward pass\n",
    "# y = loaded_model.forward(input_ids, attention_mask, nn_input)\n",
    "\n",
    "# # Visualize the model\n",
    "# dot = torchviz.make_dot(y, params=dict(loaded_model.named_parameters()))\n",
    "# dot.render(\"model_graph\", format=\"png\", cleanup=True)  # Save as PNG\n",
    "# dot  # Display graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# loaded_model\n",
    "# writer = SummaryWriter()\n",
    "# dummy_input = [input_ids, attention_mask, nn_input]\n",
    "# writer.add_graph(loaded_model, dummy_input)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
